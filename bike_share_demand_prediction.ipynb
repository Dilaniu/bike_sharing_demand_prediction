{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Seoul Bike Sharing Demand Prediction </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b> The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.</b>\n",
        "\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "* ### Date : year-month-day\n",
        "* ### Rented Bike count - Count of bikes rented at each hour\n",
        "* ### Hour - Hour of he day\n",
        "* ### Temperature-Temperature in Celsius\n",
        "* ### Humidity - %\n",
        "* ### Windspeed - m/s\n",
        "* ### Visibility - 10m\n",
        "* ### Dew point temperature - Celsius\n",
        "* ### Solar radiation - MJ/m2\n",
        "* ### Rainfall - mm\n",
        "* ### Snowfall - cm\n",
        "* ### Seasons - Winter, Spring, Summer, Autumn\n",
        "* ### Holiday - Holiday/No holiday\n",
        "* ### Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lcMmVQDG0jX"
      },
      "source": [
        "**Importing Modules**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoRWbiafHZ06"
      },
      "source": [
        "**looading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIYwrsQUHr0P"
      },
      "outputs": [],
      "source": [
        "#let's mount the google drive for import the dtaset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZUsR9bbG6ue"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/bike_share/SeoulBikeData.csv', encoding= 'unicode_escape')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mComkuDiG6xR"
      },
      "outputs": [],
      "source": [
        "# Viewing the data of top 5 rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xb8GglnJ776"
      },
      "outputs": [],
      "source": [
        "# View the data of bottom 5 rows\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAoPEHSqJ8HO"
      },
      "outputs": [],
      "source": [
        "#Getting the shape of dataset with rows and columns\n",
        "print(df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsoKBpjlKKMx"
      },
      "outputs": [],
      "source": [
        "#check details about the data set\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQI0Kj8DKKY4"
      },
      "outputs": [],
      "source": [
        "#Looking for the description of the dataset\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HxcM0cFKKcL"
      },
      "outputs": [],
      "source": [
        "#Getting all the columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKVhhQzkK0ad"
      },
      "source": [
        "there are 14 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uht7JezLPEOw"
      },
      "outputs": [],
      "source": [
        "# finding total no of rows in dataset\n",
        "print(\"The no of rows in the dataset is \",len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **preprocessing the dataset**\n"
      ],
      "metadata": {
        "id": "35Kg4c-ZgVlq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGsE8vumLD2o"
      },
      "source": [
        "**Checking for null values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT5X2kZpKKfj"
      },
      "outputs": [],
      "source": [
        "#count of missing values in each column.\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RHUYSBoLvpU"
      },
      "source": [
        "that there is no null values is our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4O79P_sPyuG"
      },
      "source": [
        "**checking duplicate values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pn-lpJOLeio"
      },
      "outputs": [],
      "source": [
        "# Checking Duplicate Values\n",
        "duplicates =len(df[df.duplicated()])\n",
        "print(duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2hcKF94Pt2_"
      },
      "source": [
        "there are no duplicate values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qqv7kdMSvt2"
      },
      "source": [
        "**convert the \"date\" column into 3 different columns i.e \"year\",\"month\",\"day\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1RgqR72dIBk"
      },
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "df['date'] = df['Date'].apply(lambda x: dt.datetime.strptime(x,\"%d/%m/%Y\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIPPmjc7dgQs"
      },
      "outputs": [],
      "source": [
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "\n",
        "df['day'] = df['date'].dt.day_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECDpPiHBQMV1"
      },
      "outputs": [],
      "source": [
        "#creating a new column of \"weekdays_weekend\" and drop the column \"Date\",\"day\",\"year\"\n",
        "df['week']=df['day'].apply(lambda x : \"weekend\" if x=='Saturday' or x=='Sunday' else \"weekday\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afkeCFOpRvwP"
      },
      "outputs": [],
      "source": [
        "# checking no of years\n",
        "df['week'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbsPuo0mhYUS"
      },
      "outputs": [],
      "source": [
        "df=df.drop(columns=['date','day','year'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "H5WiwPiSeuot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we convert the \"date\" column into 3 different column i.e \"year\",\"month\",\"day\".\n",
        "The \"year\" column in our data set is basically contain the 2 unique number contains the details of from 2017 december to 2018 november so if i consider this is a one year then we don't need the \"year\" column so we drop it.\n",
        "The other column \"day\", it contains the details about the each day of the month, for our relevence we don't need each day of each month data but we need the data about, if a day is a weekday or a weekend so we convert it into this format and drop the \"day\" column."
      ],
      "metadata": {
        "id": "7_ZRvznceoeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the int64 column into catagory column\n",
        "cols=['Hour','month','week']\n",
        "for col in cols:\n",
        "  df[col]=df[col].astype('category')"
      ],
      "metadata": {
        "id": "x-fj-RlBgQMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "xEvQsFLfgQp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slR3etQNhIKa"
      },
      "outputs": [],
      "source": [
        "#Heatmap for co-relation in features\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation between all the vaibles', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above experiment i can conclude that Temperature and Dew point temperature(°C) has the high correlation . we drop this column then it dont affects the outcome of our analysis"
      ],
      "metadata": {
        "id": "aFSDHOCqkN8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGt2MEJShIS2"
      },
      "outputs": [],
      "source": [
        "df.drop(columns= ['Dew point temperature(°C)'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# removing outliers"
      ],
      "metadata": {
        "id": "gsDrVbuSg14R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRVbE4YkoiC_"
      },
      "outputs": [],
      "source": [
        "# looking for outliers using box plot\n",
        "plt.figure(figsize=(10,10))\n",
        "for index,item in enumerate([i for i in df.describe().columns.to_list() if i not in ['Rainfall(mm)','Snowfall (cm)']]):\n",
        "  plt.subplot(3,4,index+1)\n",
        "  sns.boxplot(df[item])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the inter-quartile range\n",
        "\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "print(IQR)"
      ],
      "metadata": {
        "id": "UUP68BnsoZ7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# listing features to remove outliers\n",
        "\n",
        "features = list(df.columns)\n",
        "features = features[2:]\n",
        "list_0 = ['Hour','Seasons','Holiday','Functioning Day','month','year','week']\n",
        "new_features = [x for x in features if x not in list_0]"
      ],
      "metadata": {
        "id": "QFcIAMt8oZ-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_features"
      ],
      "metadata": {
        "id": "iS5k5jIsoaKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing outliers\n",
        "\n",
        "df[new_features] = df[new_features][~((df[new_features] < (Q1 - 1.5 * IQR)) |(df[new_features] > (Q3 + 1.5 * IQR))).any(axis=1)]"
      ],
      "metadata": {
        "id": "Pdxs2TM5o_Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "AdloX96Zo_fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbjZWybkoyNd"
      },
      "source": [
        "# handling Null values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filling null values with mean values\n",
        "\n",
        "df['Temperature(°C)'] = df['Temperature(°C)'].fillna(df['Temperature(°C)'].mean())\n",
        "df['Humidity(%)'] = df['Humidity(%)'].fillna(df['Humidity(%)'].mean())\n",
        "df['Wind speed (m/s)'] = df['Wind speed (m/s)'].fillna(df['Wind speed (m/s)'].mean())\n",
        "df['Visibility (10m)'] = df['Visibility (10m)'].fillna(df['Visibility (10m)'].mean())\n",
        "\n",
        "df['Solar Radiation (MJ/m2)'] = df['Solar Radiation (MJ/m2)'].fillna(df['Solar Radiation (MJ/m2)'].mean())\n",
        "df['Rainfall(mm)'] = df['Rainfall(mm)'].fillna(df['Rainfall(mm)'].mean())\n",
        "df['Snowfall (cm)'] = df['Snowfall (cm)'].fillna(df['Snowfall (cm)'].mean())"
      ],
      "metadata": {
        "id": "uZKLpq2QqfCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "R6tcpwajrOGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bipL2znXiPvd"
      },
      "outputs": [],
      "source": [
        "#Heatmap for co-relation in features\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation between all the vaibles', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_X3Iv5SN4ai"
      },
      "source": [
        "# performing EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**categorical variables**"
      ],
      "metadata": {
        "id": "pixPFmP7joZ0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqjD4823O9NL"
      },
      "source": [
        "**Month**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmXFG1fPia9W"
      },
      "outputs": [],
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(10,5))\n",
        "sns.barplot(data=df,x='month',y='Rented Bike Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Month ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKYU5zDKPYTr"
      },
      "source": [
        "From the above bar plot we can clearly say that from the month 5 to 10 the demand of the rented bike is high as compare to other months"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**week**"
      ],
      "metadata": {
        "id": "uUctYK6OhWGS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHMFGY5PQyv-"
      },
      "outputs": [],
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(10,8))\n",
        "sns.barplot(data=df,x='week',y='Rented Bike Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to weekdays_weekenday ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_sEfAfAPPxU"
      },
      "outputs": [],
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.pointplot(data=df,x='Hour',y='Rented Bike Count',hue='week',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to weekdays_weekend ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OXQbVC7Sfdx"
      },
      "source": [
        "From the above point plot and bar plot we can say that in the week days which represent in blue colur show that the demand of the bike higher because of the office. Peak Time are 7 am to 9 am and 5 pm to 7 pm The orange colur represent the weekend days, and it show that the demand of rented bikes are very low specially in the morning hour but when the evening start from 4 pm to 8 pm the demand slightly increases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmQae0G7ShAT"
      },
      "source": [
        "**Functioning day**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B8ZjtwIWLYG"
      },
      "outputs": [],
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(10,8))\n",
        "sns.barplot(data=df,x='Functioning Day',y='Rented Bike Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Functioning Day ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJXzitKISmXb"
      },
      "outputs": [],
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.pointplot(data=df,x='Hour',y='Rented Bike Count',hue='Functioning Day',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to Functioning Day ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JqKfiwxTD3K"
      },
      "source": [
        "In the above bar plot and point plot which shows the use of rented bike in functioning day or not, and it clearly shows that,\n",
        "Peoples dont use reneted bikes in no functioning day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPBZYfBLTJHW"
      },
      "source": [
        "**seasons**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piPjdX5oSmc9"
      },
      "outputs": [],
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(15,8))\n",
        "sns.boxplot(data=df,x='Seasons',y='Rented Bike Count',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to Seasons ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMf_a319VDLl"
      },
      "outputs": [],
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(15,8))\n",
        "sns.barplot(data=df,x='Seasons',y='Rented Bike Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Seasons ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaPCZBiCTnrC"
      },
      "source": [
        "In the above box plot and bar plot which shows the use of rented bike in in four different seasons, and it clearly shows that,\n",
        "In summer season the use of rented bike is high\n",
        "In winter season the use of rented bike is very low because of snowfall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InOUTs5hTv4u"
      },
      "source": [
        "**Holiday**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rINTA19VSmgm"
      },
      "outputs": [],
      "source": [
        "df.groupby('Holiday').sum()['Rented Bike Count'].plot.pie(radius=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feEWU0-LW1se"
      },
      "outputs": [],
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.pointplot(data=df,x='Hour',y='Rented Bike Count',hue='Holiday',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to Holiday ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iGxvMVpTkdU"
      },
      "source": [
        "In the above pie plot and point plot which shows the use of rented bike in a holiday, and it clearly shows that,\n",
        "plot shows that in holiday people uses the rented bike from 2pm-8pm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of numerical variables**"
      ],
      "metadata": {
        "id": "bwBUPkKwjALo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34ZhBRa_jSXD"
      },
      "outputs": [],
      "source": [
        "numerical_columns=['Rented Bike Count','Temperature(°C)','Humidity(%)',\t'Wind speed (m/s)',\t'Visibility (10m)',\t'Solar Radiation (MJ/m2)'\t,'Rainfall(mm)'\t,'Snowfall (cm)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te6B18h8ia6C"
      },
      "outputs": [],
      "source": [
        "# checking the distribution\n",
        "plt.figure(figsize=(10,10))\n",
        "for index,item in enumerate(numerical_columns):\n",
        "  plt.subplot(3,3,index+1)\n",
        "  sns.distplot(df[item])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dataframe containing the count of bikes rented in different temperature\n",
        "\n",
        "df_temp = pd.DataFrame(df.groupby('Temperature(°C)')['Rented Bike Count'].sum())\n",
        "df_temp.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "oMLPOF0qbW1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot showing distribution of bike rentals according to temperature intensity\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.distplot(df_temp['Temperature(°C)'])"
      ],
      "metadata": {
        "id": "LcndlgmxbXHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Above plot shows that people tend to rent bikes when the temperature is between -5 to 25 degrees."
      ],
      "metadata": {
        "id": "x0pvl7SScsvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dataframe containing the count of bikes rented in differant visibility ranges\n",
        "\n",
        "df_visi = pd.DataFrame(df.groupby('Visibility (10m)')['Rented Bike Count'].sum())\n",
        "df_visi.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "2EN59F8Dcylz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.distplot(df_visi['Visibility (10m)'])"
      ],
      "metadata": {
        "id": "H0sDFHquc7L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above plot shows that people tend to rent bikes when the visibility is between 300 to 1700."
      ],
      "metadata": {
        "id": "yYNoIAUmc_Kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label Encoding**"
      ],
      "metadata": {
        "id": "4tcRlQpQtaFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dummy variables for categorical feature --> Seasons, month, DayOfWeek, year, fuctioning day, holiday\n",
        "\n",
        "seasons = pd.get_dummies(df['Seasons'])\n",
        "\n",
        "working_day = pd.get_dummies(df['Holiday'])\n",
        "\n",
        "F_day = pd.get_dummies(df['Functioning Day'])\n",
        "\n",
        "month = pd.get_dummies(df['month'])\n",
        "\n",
        "week_day = pd.get_dummies(df['week'])\n",
        "\n"
      ],
      "metadata": {
        "id": "njAantJotIXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df,seasons,working_day,F_day,month,week_day],axis=1)\n"
      ],
      "metadata": {
        "id": "TSvmduTXtIod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the data dummy variable is created or not\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "aUjV5wCBtSxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## dropping columns for which dummy variables were created\n",
        "\n",
        "df.drop(['Seasons','Holiday','Functioning Day','week','month'],axis=1,inplace=True)\n"
      ],
      "metadata": {
        "id": "l2MBSUfduqax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Date'],axis=1,inplace=True) # droping date because we already extract the date from the data\n"
      ],
      "metadata": {
        "id": "5SRzhYvfu6lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**checking multicollinearity**"
      ],
      "metadata": {
        "id": "Idhwyq_MkAVf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LI_hLyj4iZ7g"
      },
      "outputs": [],
      "source": [
        "# function to calculate Multicollinearity\n",
        "\n",
        "# checking the vif\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "X = df\n",
        "\n",
        "\n",
        "# VIF dataframe\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "\n",
        "# calculating VIF for each feature\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
        "                          for i in range(len(X.columns))]\n",
        "vif_data['VIF'] = round(vif_data['VIF'],2)\n",
        "\n",
        "\n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['Rainfall(mm)','Snowfall (cm)'],axis=1)"
      ],
      "metadata": {
        "id": "yu0zyAcHvW_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regression plot**"
      ],
      "metadata": {
        "id": "bUvRQ0dKsaXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns=['Rented Bike Count','Temperature(°C)','Humidity(%)',\t'Wind speed (m/s)',\t'Visibility (10m)',\t'Solar Radiation (MJ/m2)'\t]"
      ],
      "metadata": {
        "id": "JrDyhTwUvvtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5URhi1hIXUA6"
      },
      "outputs": [],
      "source": [
        "#printing the regression plot for all the numerical features\n",
        "for col in numerical_columns:\n",
        "  fig,ax=plt.subplots(figsize=(10,6))\n",
        "  sns.regplot(x=df[col],y=df['Rented Bike Count'],scatter_kws={\"color\": 'orange'}, line_kws={\"color\": \"black\"})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature,solar radiation,windspeed,visibility  are positively related to target variable ,the rented bike count increases with increase of these features"
      ],
      "metadata": {
        "id": "eLR1Pxe303jW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22_IKaVfhpLD"
      },
      "outputs": [],
      "source": [
        "#Assign the value in X and Y\n",
        "X = df.drop(columns=['Rented Bike Count'], axis=1)\n",
        "y = np.sqrt(df['Rented Bike Count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4csYMY_phpR5"
      },
      "outputs": [],
      "source": [
        "X.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.dtypes"
      ],
      "metadata": {
        "id": "vny4NqlZgvbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk_yZ8n7kMk5"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3VgJ1T_ivJn"
      },
      "outputs": [],
      "source": [
        "#Creat test and train data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61G6ekzanr5j"
      },
      "outputs": [],
      "source": [
        "X_train.columns = X_train.columns.astype(str)\n",
        "X_test.columns = X_test.columns.astype(str)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)  # Use just transform for the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear regression model"
      ],
      "metadata": {
        "id": "qO-skBTXlH55"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PSnfTggivMz"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg= LinearRegression().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVensay4ivTs"
      },
      "outputs": [],
      "source": [
        "#check the score\n",
        "reg.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKmnjVW7mhoJ"
      },
      "outputs": [],
      "source": [
        "#check the coefficeint\n",
        "reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW52HOkumhrn"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train=reg.predict(X_train)\n",
        "y_pred_test=reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test"
      ],
      "metadata": {
        "id": "Lbhcsy_HwcWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibqmwkLwmhw5"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "#calculate MSE\n",
        "MSE_lr= mean_squared_error((y_train), (y_pred_train))\n",
        "print(\"MSE :\",MSE_lr)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_lr=np.sqrt(MSE_lr)\n",
        "print(\"RMSE :\",RMSE_lr)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_lr= mean_absolute_error(y_train, y_pred_train)\n",
        "print(\"MAE :\",MAE_lr)\n",
        "\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr= r2_score(y_train, y_pred_train)\n",
        "print(\"R2 :\",r2_lr)\n",
        "Adjusted_R2_lr = (1-(1-r2_score(y_train, y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "\n",
        "print(\"Adjusted R2 :\",Adjusted_R2_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# linear regression with L2 regularization"
      ],
      "metadata": {
        "id": "Pp_Zrrzrlpp7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVJ9umQFrYAV"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge= Ridge(alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH17y5yUrYKw"
      },
      "outputs": [],
      "source": [
        "#FIT THE MODEL\n",
        "ridge.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ-EHrmWrYN1"
      },
      "outputs": [],
      "source": [
        "#check the score\n",
        "ridge.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZyV1AJwrYRb"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_ridge=ridge.predict(X_train)\n",
        "y_pred_test_ridge=ridge.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating metrics\n",
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE  = mean_squared_error(y_test,y_pred_test_ridge)\n",
        "print(\"MSE :\" , MSE)\n",
        "#calculate RMSE\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "#calculate r2 and adjusted r2\n",
        "r2_ridge_test = r2_score(y_test,y_pred_test_ridge)\n",
        "print(\"R2 :\" ,r2_ridge_test)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test,y_pred_test_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n"
      ],
      "metadata": {
        "id": "vamVc-JOxNYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rgAdHxvWNXg"
      },
      "source": [
        "# linear regression with elastic net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVG7W-D_rYW8"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import ElasticNet\n",
        "#a * L1 + b * L2\n",
        "#alpha = a + b and l1_ratio = a / (a + b)\n",
        "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHtEDLAJVcv4"
      },
      "outputs": [],
      "source": [
        "#FIT THE MODEL\n",
        "elasticnet.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsyQ_6djVczb"
      },
      "outputs": [],
      "source": [
        "#check the score\n",
        "elasticnet.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52eCHEa5Vc3R"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_en=elasticnet.predict(X_train)\n",
        "y_pred_test_en=elasticnet.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLGx18hkVk8p"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e= mean_squared_error((y_train), (y_pred_train_en))\n",
        "print(\"MSE :\",MSE_e)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e=np.sqrt(MSE_e)\n",
        "print(\"RMSE :\",RMSE_e)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e= mean_absolute_error(y_train, y_pred_train_en)\n",
        "print(\"MAE :\",MAE_e)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e= r2_score(y_train, y_pred_train_en)\n",
        "print(\"R2 :\",r2_e)\n",
        "Adjusted_R2_e=(1-(1-r2_score(y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMhFAsWPXtCB"
      },
      "source": [
        "# Random ForestRegressor with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTLOey1XXFSF"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#implementing the model\n",
        "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state=5)\n",
        "#training the model\n",
        "rf_reg.fit(X_train, y_train)\n",
        "#defining the predicted variables\n",
        "pred_train = rf_reg.predict(X_train)\n",
        "pred_test = rf_reg.predict(X_test)\n",
        "MSE_train = mean_squared_error(y_train, pred_train)\n",
        "print(f'MSE= {MSE_train}')\n",
        "\n",
        "RMSE_train = np.sqrt(MSE_train)\n",
        "print(f'RMSE= {RMSE_train}')\n",
        "\n",
        "R2_Score_train = r2_score(y_train, pred_train)\n",
        "print(f'R square_Score_train= {R2_Score_train}')\n",
        "\n",
        "MSE_test = mean_squared_error(y_test, pred_test)\n",
        "print(f'MSE= {MSE_test}')\n",
        "\n",
        "RMSE_test = np.sqrt(MSE_test)\n",
        "print(f'RMSE= {RMSE_test}')\n",
        "R2_Score_test = r2_score(y_test, pred_test)\n",
        "print(f'R square_Score_test= {R2_Score_test}')"
      ],
      "metadata": {
        "id": "k8hUpiyZMET4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot actual values\n",
        "sns.scatterplot(x=y_train*y_train, y=y_train*y_train, label='Actual', alpha=0.6)\n",
        "\n",
        "# Plot predicted values\n",
        "sns.scatterplot(x=y_train*y_train, y=pred_train*pred_train, color='red', label='Predicted', alpha=0.6)\n",
        "\n",
        "# Regression line for actual vs predicted\n",
        "sns.lineplot(x=y_train*y_train, y=pred_train*pred_train, color='blue')\n",
        "\n",
        "plt.title('Visualizing the predicted and the actual variables with Random Forest Regression', size=16)\n",
        "plt.xlabel('Actual Values', size=14)\n",
        "plt.ylabel('Predicted Values', size=14)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Tjv6hLTOMEe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGboost"
      ],
      "metadata": {
        "id": "UAcsyvEj1OPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Create a DMatrix for more efficiency (optional, but can be helpful especially for large datasets)\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Set up the parameters for the XGBoost model\n",
        "param = {\n",
        "    'max_depth': 10,  # Maximum depth of a tree\n",
        "    'eta': 0.3,  # Step size shrinkage used in update to prevents overfitting\n",
        "    'objective': 'reg:squarederror',  # Loss function to minimize\n",
        "    'eval_metric': 'rmse'  # Root mean squared error\n",
        "}\n",
        "\n",
        "# Specify validation set for performance monitoring\n",
        "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
        "\n",
        "# Train the model\n",
        "num_round = 30  # Number of boosting rounds\n",
        "bst = xgb.train(param, dtrain, num_round, evallist)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bst.predict(dtest)\n"
      ],
      "metadata": {
        "id": "6RTDEBPAjGZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on test set\n",
        "y_pred_test = bst.predict(dtest)\n",
        "xgb_r2_test = r2_score(y_test, y_pred_test)\n",
        "xgb_rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "\n",
        "# Predictions on train set\n",
        "y_pred_train = bst.predict(dtrain)\n",
        "xgb_r2_train = r2_score(y_train, y_pred_train)\n",
        "xgb_rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "print(f\"Train R^2 Score: {xgb_r2_train}\")\n",
        "print(f\"Train RMSE: {xgb_rmse_train}\")\n",
        "print(f\"Test R^2 Score: {xgb_r2_test}\")\n",
        "print(f\"Test RMSE: {xgb_rmse_test}\")\n"
      ],
      "metadata": {
        "id": "12JbKhtEo9OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBOOST regressor with grid search"
      ],
      "metadata": {
        "id": "4t-rdkRJk37Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the XGBoost regressor\n",
        "xgb_model = xgb.XGBRegressor()# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [50, 100],\n",
        "    'gamma': [0, 0.5, 1],\n",
        "}\n",
        "\n",
        "# Set up the grid search\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=3, verbose=1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train a model using the best parameters\n",
        "best_xgb_model = xgb.XGBRegressor(**best_params)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred = best_xgb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "slTRzBlLk8zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the R^2 score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R-square Score: {r2}\")\n",
        "\n",
        "# Compute the RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"RMSE: {rmse}\")"
      ],
      "metadata": {
        "id": "cZuO-psWolsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing the predictions\n",
        "sns.scatterplot(x=y_pred,y=y_test)\n",
        "plt.title('Predicted vs Actual - gradientBoosting')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.xlabel('Actual Values')"
      ],
      "metadata": {
        "id": "P5JJqXzhCiCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**compaing the model with r2 value**"
      ],
      "metadata": {
        "id": "8S9ubXZ00APf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models= ['Linear regressor','Ridge','elastic net', 'random forest regressor','xgregressor with grid search']\n",
        "R2_value= [Adjusted_R2_lr,r2_ridge_test,r2_e, R2_Score_test, r2]\n",
        "compare_models = pd.DataFrame([R2_value],columns=models,index =['r2_value'])\n",
        "compare_models"
      ],
      "metadata": {
        "id": "GJTn7WtaURgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# conclusion"
      ],
      "metadata": {
        "id": "wLuhvkICH2hf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Hour of the day holds most importance among all the features for prediction of dataset\n",
        "*   It is observed that highest number bike rentals counts in Autumn/fall Summer Seasons and the lowest in Spring season.\n",
        "*   We observed that the highest number of bike rentals on a clear day and the lowest on a snowy or rainy day\n",
        "*   As we can see the top 5 important features of our dataset are: Season_winter, Temperature, Hour, Season_autumn, Humidity\n",
        "*   Peoples dont use rented bikes in no functioning day\n",
        "*   people tend to rent bikes when the temperature is between -5 to 25 degrees\n",
        "*    people tend to rent bikes when the visibility is between 300 to 1700\n",
        "*  for all the above experiments we can conclude that extreme gradient boosting  and random forest regressor with hyperparameter tuning, we got the best results. (Lowest RMSE and highest R- square scores)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ViKlspY2HTxI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}